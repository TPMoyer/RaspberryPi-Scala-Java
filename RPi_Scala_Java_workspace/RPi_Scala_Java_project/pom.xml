<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>none</groupId>
  <artifactId>ScalaJavaPi4j</artifactId>
  <version>V0.01</version>
  <name>aNameHere</name>
  <description></description>
  <inceptionYear>2018</inceptionYear>

<!-- 
This pom file is a hacked down legacy from a series of big data engagements (my day job).
Have commented out the spark, aws, and hadoop stuff
 -->
 
<!--  For cdh5.5    
 <properties>
	<scala.version>2.10.5</scala.version>
	<scala.dep.version>2.10</scala.dep.version>
	<avro.version>1.7.6-cdh5.5.1</avro.version>
	<parquet.version>1.5.0-cdh5.5.1</parquet.version>
	<java.version>1.8</java.version>
	<slf4j-version>1.7.12</slf4j-version>
	<log4j.version>2.0-rc1</log4j.version>
	<spark.version>1.5.0-cdh5.5.1</spark.version>
	<maven.compiler.plugin.version>3.3</maven.compiler.plugin.version>
	<maven.scala.plugin.version>2.15.2</maven.scala.plugin.version>
	<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
	<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
   	<maven.compiler.source>1.8</maven.compiler.source>
   	<maven.compiler.target>1.8</maven.compiler.target>
  </properties>
-->

<!-- 
  <repositories>
    <repository>
    	<id>bintray-spark-packages</id>
     	<name>Spark-Packages</name>
     	<url>https://dl.bintray.com/spark-packages/maven/</url>
    </repository>
  </repositories>
 -->
   
	<properties>
		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<encoding>UTF-8</encoding>
		<scala.tools.version>2.11</scala.tools.version>
		<scala.version>2.11.8</scala.version>
		<spark.version>2.0.2</spark.version>
		<slf4j-version>1.7.25</slf4j-version>
		<!-- <aws-sdk.version>1.11.66</aws-sdk.version>  -->
		<!-- <awscala.version>0.5.9</awscala.version>  -->
	</properties>

  <dependencies>
    <dependency>
      <groupId>com.pi4j</groupId>
      <artifactId>pi4j-core</artifactId>
      <version>1.1</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/com.pi4j/pi4j-gpio-extension -->
    <dependency>
      <groupId>com.pi4j</groupId>
      <artifactId>pi4j-gpio-extension</artifactId>
      <version>1.0</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/com.pi4j/pi4j-device -->
    <dependency>
      <groupId>com.pi4j</groupId>
      <artifactId>pi4j-device</artifactId>
      <version>0.0.5</version>
    </dependency>
   
    
    
    <!--  keeping the spark stuff because the hadoop.fs filesystem comes with -->
    <dependency>
      <groupId>org.scala-lang</groupId>
      <artifactId>scala-library</artifactId>
      <version>${scala.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.tools.version}</artifactId>
      <version>${spark.version}</version>
       <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.tools.version}</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope> 
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-sql_${scala.tools.version}</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope> 
    </dependency>
  <dependency>
    <groupId>org.apache.spark</groupId>
    <artifactId>spark-mllib_${scala.tools.version}</artifactId>
    <version>${spark.version}</version>
  </dependency>
  <!-- 
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-ec2</artifactId>
      <version>${aws-sdk.version}</version>
    </dependency>
    <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-s3</artifactId>
      <version>${aws-sdk.version}</version>
    </dependency>
        <dependency>
      <groupId>com.amazonaws</groupId>
      <artifactId>aws-java-sdk-redshift</artifactId>
      <version>${aws-sdk.version}</version>
    </dependency>
 -->

		<!-- https://mvnrepository.com/artifact/com.typesafe/config -->
		<dependency>
			<groupId>com.typesafe</groupId>
			<artifactId>config</artifactId>
			<version>1.2.1</version>
		</dependency>
		<dependency>
			<groupId>org.slf4j</groupId>
			<artifactId>slf4j-api</artifactId>
			<version>${slf4j-version}</version>
		</dependency>
		<!--  do find myself sometimes reading/writing .csv files -->
		<dependency>
			<groupId>com.opencsv</groupId>
			<artifactId>opencsv</artifactId>
			<version>3.8</version>
		</dependency>
		<!-- https://github.com/seratch/AWScala  
		<dependency>
			<groupId>com.github.seratch</groupId>
			<artifactId>awscala_2.11</artifactId>
			<version>${awscala.version}</version>
		</dependency>
	-->
		
    <!-- Test   Kept this because some folks are keen on testing.  
    Never picked up the habit myself.
    Use a lot of logging while developing the code instead.
    
    I comment the logging after a section works well, and thereafter it serves as a kind of documentation.
    If I have problems with a seciton, I uncomment the log lines, and have found over the decades
    that if the logging was good enough for me to figure out the code when writing it,
    It is usually good enough to help me figure out what is going wrong.
    Breakpoints in debug-style development do not have this kind of stickyness.
     -->
    <dependency>
      <groupId>junit</groupId>
      <artifactId>junit</artifactId>
      <version>4.11</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.specs2</groupId>
      <artifactId>specs2-core_${scala.tools.version}</artifactId>
      <version>3.7.2</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.specs2</groupId>
      <artifactId>specs2-junit_${scala.tools.version}</artifactId>
      <version>3.7.2</version>
      <scope>test</scope>
    </dependency>
    <dependency>
      <groupId>org.scalatest</groupId>
      <artifactId>scalatest_${scala.tools.version}</artifactId>
      <version>3.0.0-M15</version>
      <scope>test</scope>
    </dependency>
  </dependencies>

  <build>
    <sourceDirectory>src/main/scala</sourceDirectory>
    <testSourceDirectory>src/test/scala</testSourceDirectory>
    <plugins>
		
      <plugin>
        <!-- see http://davidb.github.com/scala-maven-plugin -->
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
        <version>3.2.0</version>
        <executions>
          <execution>
            <goals>
              <goal>compile</goal>
              <goal>testCompile</goal>
            </goals>
            <configuration>
              <args>
                <arg>-dependencyfile</arg>
                <arg>${project.build.directory}/.scala_dependencies</arg>
              </args>
            </configuration>
          </execution>
        </executions>
      </plugin>
		
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-shade-plugin</artifactId>
        <version>2.4.2</version>
        <configuration>
        </configuration>
        <executions>
          <execution>
            <phase>package</phase>
            <goals>
              <goal>shade</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
		
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>2.18.1</version>
        <configuration>
          <useFile>false</useFile>
          <disableXmlReport>true</disableXmlReport>
          <!-- If you have classpath issue like NoDefClassError,... -->
          <!-- useManifestOnlyJar>false</useManifestOnlyJar -->
          <includes>
            <include>**/*Test.*</include>
            <include>**/*Suite.*</include>
          </includes>
          <filters>
            <filter>
              <artifact>*:*</artifact>
              <excludes>
                <exclude>META-INF/*.SF</exclude>
                <exclude>META-INF/*.DSA</exclude>
                <exclude>META-INF/*.RSA</exclude>
              </excludes>
            </filter>
          </filters>
        </configuration>
      </plugin>
    </plugins>
  </build>
</project>
